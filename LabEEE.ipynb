{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04PmjXwf-Rwq"
   },
   "source": [
    "# Bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "Q2tcc8yH-FpN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pauRK7Fl-Ybr"
   },
   "source": [
    "# Mashup bases \"fisiologicas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAAhzRi7QHyS",
    "outputId": "26a198cd-5c10-417e-aad7-7930d5c9427e"
   },
   "outputs": [],
   "source": [
    "padrao_busca_csv = \"/Users/michi/Desktop/01. Outdoor-Indoor/01. LabEEE Experiments/**/*.csv\"\n",
    "padrao_busca_excel = \"/Users/michi/Desktop/01. Outdoor-Indoor/01. LabEEE Experiments/**/*.xlsx\"\n",
    "todos_arquivos = glob.glob(padrao_busca_csv, recursive=True) + glob.glob(padrao_busca_excel, recursive=True)\n",
    "\n",
    "ids = [\"IS\", \"LG\", \"LM\", \"MF\", \"TM\", \"ZM\", \"AW\", \"JF\", \"JP\", \"MN\", \"NC\", \"RM\"] \n",
    "nao = [\"01. Pilot LabEEE 20231114\", \"02. Pilot LabEEE 20231122\"]\n",
    "\n",
    "arquivos_fisiologicos = [arquivo for arquivo in todos_arquivos if any(sigla in arquivo for sigla in ids) and not any(nome in arquivo for nome in nao)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "relacao_tabela_informacao = {\"A (°C)\" :\t[\"4B00000069A8E941\",\"FE00000069AF1041\",\"B600000069B23241\",\"7D00000069AB4641\",\"0F00000069AAAF41\",\"C400000069ADCC41\"],\n",
    "                            \"D (°C)\":\t[\"CB00000069AD3041\",\"9400000069AA4941\",\"2700000069AD8541\",\"C100000069B26141\",\"CA00000069B19041\",\"4A00000069AC0841\"],\n",
    "                            \"F (°C)\":\t[\"C400000069AA8341\",\"C400000069B3DB41\",\"8100000069AE1641\",\"2700000069AACA41\",\"6700000069AEFC41\",\"1C00000069B3F941\"], \n",
    "                            \"H (°C)\":\t[\"B200000069AE3141\",\"EC00000069A9CD41\",\"3300000069AC2241\",\"3600000069AAD741\",\"E800000069AAC041\",\"AD00000069AF4C41\"],\n",
    "                            \"J (°C)\":\t[\"FA00000069AD0441\",\"3400000069B1AE41\",\"C700000069B34D41\",\"4B00000069B0A841\",\"0600000069B22741\",\"9100000069AAEA41\",\"6700000069AB8141\"],\n",
    "                            \"K (°C)\":\t[\"FB00000069B28F41\",\"7B00000069AA6A41\",\"E500000069AA2F41\",\"1A00000069A9BF41\",\"FE00000069B10741\",\"E100000069AD4641\"],\n",
    "                            \"M (°C)\":\t[\"1B00000069B06241\",\"8C00000069ADD241\",\"F000000069AF6941\",\"AA00000069AA8141\",\"1600000069ABE741\",\"A000000069AEBA41\"],\n",
    "                            \"O (°C)\":\t[\"7600000069AA8541\",\"F200000069B16D41\",\"3000000069A9C941\",\"BF00000069AFC741\",\"A300000069B12241\",\"D900000069ACA241\"],\n",
    "                            \"Q (°C)\":\t[\"8600000069B0B141\",\"6000000069AB3141\",\"DB00000069A9CC41\",\"EF00000069B23141\",\"6900000069AE8541\",\"4300000069B3CF41\"],\n",
    "                            \"T (°C)\":\t[\"7600000069AB9C41\",\"4500000069B1C841\",\"6600000069B25C41\",\"A200000069B0BE41\",\"D700000069B3D541\",\"9800000069B26241\",\"9E00000069AE7241\"],\n",
    "                            \"T_RH\" : [\"6E0000006CB57E41\",\t\"590000006CB46641\",\t\"4B0000006CBA7341\",\t\"D30000006CBD4C41\",\t\"370000006341C241\",\t\"9C000000633F9F41\"]}\n",
    "\n",
    "nomes = [\"Zac\", \"Joao\", \"Igor\", \"Luis\", \"Milena\", \"Ana\", \"Marcela\", \"Nathalia\", \"Thalita\", \"Liege\", \"Rayner\", \"João\"]\n",
    "sports = [\"WALKING\",\"CYCLING\",\"CROSS-COUNTRY_SKIING\",\"SKATING\",\"RIDING\",\"ROWING\"]\n",
    "\n",
    "ids_com_codigo = {\"IS\":'IS26', \"LG\":'LG37', \"LM\":'LM27', \"MF\":'MF36', \"TM\":'TM35', \"ZM\":'ZM26', \"AW\":'AW35', \"JF\":'JF25', \"JP\":'JP27', \"MN\":\"MN37\", \"NC\":\"NC36\", \"RM\":\"RM26\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_qual_tipo_de_csv(titulo):\n",
    "    for chave, valores in relacao_tabela_informacao.items():\n",
    "        if titulo in valores:\n",
    "            return chave\n",
    "\n",
    "def convertepfloat(row):\n",
    "    n1 = str(row.iloc[2]).replace('.', '')\n",
    "    n2 = str(row.iloc[3]).replace('.', '')\n",
    "    return float(n1 + '.' + n2)\n",
    "\n",
    "def datamento(base_de_dados_crua, base_de_dados_nova):\n",
    "    dia = base_de_dados_crua.iloc[0,2]\n",
    "    dia = dia.replace('-','/')\n",
    "    hora_inicio = base_de_dados_crua.iloc[0,3]\n",
    "    data_inicio = dia + \" \" + hora_inicio\n",
    "    data_inicio = datetime.strptime(data_inicio, '%d/%m/%Y %H:%M:%S')\n",
    "    data_fim = dia + ' ' + '20:00:00'\n",
    "    data_fim = datetime.strptime(data_fim, '%d/%m/%Y %H:%M:%S')\n",
    "    intervalos_tempo = pd.date_range(start=data_inicio, end=data_fim, freq='s')\n",
    "    base_de_dados_nova['Date'] = intervalos_tempo[:len(base_de_dados_nova)]\n",
    "\n",
    "def limpeza_simples(id, arquivo, coluna):\n",
    "    colunas = [\"Date\", \"uni\", \"u\", \"d\"]\n",
    "    dados = pd.read_csv(arquivo, skiprows=20,names=colunas).fillna('0')\n",
    "    dados[f'{coluna}'] = dados.apply(lambda row: convertepfloat(row), axis=1)\n",
    "    dados = dados.iloc[:, [0,-1]]\n",
    "    dados['Date'] = pd.to_datetime(dados['Date'], format='%d/%m/%y %H:%M:%S')\n",
    "    return dados\n",
    "\n",
    "def calcular_TPond(row):\n",
    "    if all(row[['A (°C)', 'D (°C)', 'F (°C)', 'H (°C)', 'J (°C)', 'K (°C)', 'M (°C)', 'O (°C)', 'Q (°C)', 'T (°C)']].notnull()):\n",
    "        return float(0.07 * row['T (°C)'] + 0.13 * row['Q (°C)'] + 0.19 * row['O (°C)'] + 0.12 * row['M (°C)'] + 0.12 * row['K (°C)'] + 0.12 * row['J (°C)'] + 0.05 * row['H (°C)'] + 0.06 * row['F (°C)'] + 0.08 * row['D (°C)'] + 0.06 * row['A (°C)'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def atribuir_id(id, df):\n",
    "    for chave, valores in ids_com_codigo.items():\n",
    "        if id in valores:\n",
    "            df['id'] = chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FY756p1DAJs9",
    "outputId": "b8de568b-1fd3-47b4-b41c-122f53345981"
   },
   "outputs": [],
   "source": [
    "col_names = ['id', 'Date', 'TPond (°C)', 'A (°C)', 'D (°C)', 'F (°C)', 'H (°C)', 'J (°C)', 'K (°C)', 'M (°C)', 'O (°C)', 'Q (°C)',\t'T (°C)', 'wHR (bpm)', 'cHR (bpm)', 'wU (bpm)', 'wT (°C)']\n",
    "BaseDeDados = pd.DataFrame(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo in arquivos_fisiologicos:\n",
    "    ultimo_backslash = arquivo.rfind('\\\\')\n",
    "    ultimounderscore = arquivo.rfind('_')\n",
    "    titulo = arquivo[ultimo_backslash+1:ultimounderscore]\n",
    "    penultimo_backslash = arquivo.rfind('\\\\', 0, ultimo_backslash)\n",
    "    id = arquivo[penultimo_backslash+1:penultimo_backslash+3]\n",
    "    if \"Test+Room\" in titulo or any(name in titulo for name in nomes):\n",
    "        heart = pd.read_csv(arquivo).fillna('0')\n",
    "        if(heart.iloc[0,1] == \"OTHER_OUTDOOR\"):\n",
    "            pulso = pd.read_csv(arquivo, usecols=[\"HR (bpm)\"], skiprows=2)\n",
    "            datamento(heart,pulso)\n",
    "            atribuir_id(id,pulso)\n",
    "            pulso = pulso.rename(columns={'HR (bpm)': 'wHR (bpm)'})\n",
    "            BaseDeDados = pd.concat([BaseDeDados, pulso], ignore_index=True)\n",
    "        elif(heart.iloc[0,1] in sports):\n",
    "            peito = pd.read_csv(arquivo, usecols=[\"HR (bpm)\"], skiprows=2)\n",
    "            datamento(heart,peito)\n",
    "            atribuir_id(id,peito)\n",
    "            peito = peito.rename(columns={'HR (bpm)': 'cHR (bpm)'})\n",
    "            BaseDeDados = pd.concat([BaseDeDados, peito], ignore_index=True)\n",
    "        elif(heart.iloc[0,1] == \"False\" or \"True\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(heart.iloc[0,1])    \n",
    "    elif(\"_U\" in arquivo) or (\"_T\" in arquivo) or (any(titulo in valores for valores in relacao_tabela_informacao.values())):\n",
    "        if(\"_T\" in arquivo):\n",
    "            coluna = 'wT (°C)'\n",
    "            temp = limpeza_simples(id, arquivo, coluna)\n",
    "            atribuir_id(id,temp)\n",
    "            BaseDeDados = pd.concat([BaseDeDados, temp],ignore_index=True)\n",
    "        elif(\"_U\" in arquivo):\n",
    "            coluna = 'wU (bpm)'\n",
    "            umid = limpeza_simples(id, arquivo, coluna)\n",
    "            atribuir_id(id,umid)\n",
    "            BaseDeDados = pd.concat([BaseDeDados, umid],ignore_index=True)\n",
    "        else:\n",
    "            coluna = verifica_qual_tipo_de_csv(titulo)\n",
    "            temp = limpeza_simples(id, arquivo, coluna)\n",
    "            atribuir_id(id,temp)\n",
    "            BaseDeDados = pd.concat([BaseDeDados, temp],ignore_index=True)\n",
    "    else:\n",
    "        print(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados = BaseDeDados.groupby(['id', 'Date']).agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados['TPond (°C)'] = BaseDeDados.apply(calcular_TPond, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados.to_csv('BaseDeDados.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mashup ambientais + \"fisiologicas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos do tipo Hall devem ser convertidos manualmente para csv\n"
     ]
    }
   ],
   "source": [
    "siglas_ambientais = ['CSLAB','CSSR','HALL','OUT','TtSR']\n",
    "print('Arquivos do tipo Hall devem ser convertidos manualmente para csv')\n",
    "arquivos_CSLAB = [arquivo for arquivo in todos_arquivos if 'CSLAB' in arquivo] \n",
    "arquivos_OUT = [arquivo for arquivo in todos_arquivos if 'OUT' in arquivo]\n",
    "arquivos_CSSR = [arquivo for arquivo in todos_arquivos if 'CSSR' in arquivo]\n",
    "arquivos_HALL = [arquivo for arquivo in todos_arquivos if 'HALL' in arquivo and 'excel' not in arquivo]\n",
    "arquivos_TtSR = [arquivo for arquivo in todos_arquivos if 'TtSR' in arquivo] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 6 7 6 7\n"
     ]
    }
   ],
   "source": [
    "print(len(arquivos_CSLAB), len(arquivos_CSSR), len(arquivos_HALL), len(arquivos_OUT), len(arquivos_TtSR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados_ambientais = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df, tipo):\n",
    "    df = df.rename(columns={'Data': 'Date'})\n",
    "    for coluna in df.columns[1:]:\n",
    "        if('Unnamed' in coluna):\n",
    "            df = df.drop(columns=[coluna])\n",
    "            continue\n",
    "        df = df.rename(columns={coluna: f\"{coluna} {tipo}\"})\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo in arquivos_CSSR:\n",
    "    try:\n",
    "        importado = pd.read_csv(arquivo, sep=';')\n",
    "        importado = rename_cols(importado, 'CSSR')\n",
    "        importado = importado.iloc[:, [0,1,2,3,4,5]]\n",
    "        BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, importado], ignore_index=True)\n",
    "    except:\n",
    "        print(arquivo)\n",
    "\n",
    "for arquivo in arquivos_OUT:\n",
    "    try:\n",
    "        importado = pd.read_csv(arquivo, sep=';', usecols=['Data','T_Globo','Direcao','Veloc'])\n",
    "        importado = rename_cols(importado, 'OUT')\n",
    "        importado = importado.iloc[10:]\n",
    "        BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, importado], ignore_index=True)\n",
    "    except:\n",
    "        print(arquivo)\n",
    "\n",
    "for i, arquivo in enumerate(arquivos_CSLAB):\n",
    "    try:\n",
    "        importado = pd.read_csv(arquivo, sep=';')\n",
    "        if(i==5):\n",
    "            importado = pd.read_csv(arquivo, sep=',')\n",
    "        importado = rename_cols(importado, 'CSLAB')\n",
    "        BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, importado], ignore_index=True)  \n",
    "    except:\n",
    "        print(arquivo)\n",
    "\n",
    "arquivos_TtSR.pop(0)\n",
    "for arquivo in arquivos_TtSR:\n",
    "    TtSR = pd.read_csv(arquivo,encoding='latin1',delimiter=';',skiprows=1,skipfooter=40,engine='python') \n",
    "    TtSR = TtSR.iloc[:, [0,2,4,5]]\n",
    "    TtSR = TtSR.rename(columns={'Data/Hora':'Date','094 [m/s]':'V_ar [m/s] TtSR','491 [Â°C]':'T_ar [°C] TtSR','517 TC1 [Â°C]':'T_globo [°C] TtSR'})\n",
    "    BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, TtSR], ignore_index=True)\n",
    "\n",
    "colunas_usadas = ['Date-Time (Brazil Standard Time)','Ch:1 - Temperature   (°C)','Ch:2 - RH   (%)']\n",
    "for arquivo in arquivos_HALL:\n",
    "    HALL = pd.read_csv(arquivo,encoding='latin1',delimiter=';', usecols=colunas_usadas)\n",
    "    HALL = HALL.rename(columns={'Date-Time (Brazil Standard Time)':'Date','Ch:1 - Temperature   (°C)':'Temp °C HALL','Ch:2 - RH   (%)':'RH % HALL'})\n",
    "    BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, HALL], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter colunas para números\n",
    "BaseDeDados_ambientais['V_ar [m/s] TtSR'] = pd.to_numeric(BaseDeDados_ambientais['V_ar [m/s] TtSR'], errors='coerce')\n",
    "BaseDeDados_ambientais['T_ar [°C] TtSR'] = pd.to_numeric(BaseDeDados_ambientais['T_ar [°C] TtSR'], errors='coerce')\n",
    "BaseDeDados_ambientais['T_globo [°C] TtSR'] = pd.to_numeric(BaseDeDados_ambientais['T_globo [°C] TtSR'], errors='coerce')\n",
    "BaseDeDados_ambientais['Temp °C HALL'] = pd.to_numeric(BaseDeDados_ambientais['Temp °C HALL'], errors='coerce')\n",
    "BaseDeDados_ambientais['RH % HALL'] = pd.to_numeric(BaseDeDados_ambientais['RH % HALL'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>T_ar CSSR</th>\n",
       "      <th>T_Globo CSSR</th>\n",
       "      <th>UR CSSR</th>\n",
       "      <th>Veloc_1 CSSR</th>\n",
       "      <th>Veloc_2 CSSR</th>\n",
       "      <th>T_Globo OUT</th>\n",
       "      <th>Direcao OUT</th>\n",
       "      <th>Veloc OUT</th>\n",
       "      <th>T_ar CSLAB</th>\n",
       "      <th>T_Globo CSLAB</th>\n",
       "      <th>UR CSLAB</th>\n",
       "      <th>Veloc_1 CSLAB</th>\n",
       "      <th>Veloc_2 CSLAB</th>\n",
       "      <th>Veloc_3 CSLAB</th>\n",
       "      <th>V_ar [m/s] TtSR</th>\n",
       "      <th>T_ar [°C] TtSR</th>\n",
       "      <th>T_globo [°C] TtSR</th>\n",
       "      <th>Temp °C HALL</th>\n",
       "      <th>RH % HALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/16/2024 07:25:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01/16/2024 07:26:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01/16/2024 07:27:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01/16/2024 07:28:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01/16/2024 07:29:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6244</th>\n",
       "      <td>31/01/2024 16:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.97</td>\n",
       "      <td>27.53</td>\n",
       "      <td>68.63</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>31/01/2024 16:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.01</td>\n",
       "      <td>27.58</td>\n",
       "      <td>68.39</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>31/01/2024 16:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.10</td>\n",
       "      <td>27.60</td>\n",
       "      <td>68.15</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>31/01/2024 16:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.16</td>\n",
       "      <td>27.63</td>\n",
       "      <td>67.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>31/01/2024 16:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.14</td>\n",
       "      <td>27.65</td>\n",
       "      <td>68.04</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6249 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date   T_ar CSSR   T_Globo CSSR   UR CSSR   Veloc_1 CSSR  \\\n",
       "0     01/16/2024 07:25:30         NaN            NaN       NaN            NaN   \n",
       "1     01/16/2024 07:26:30         NaN            NaN       NaN            NaN   \n",
       "2     01/16/2024 07:27:30         NaN            NaN       NaN            NaN   \n",
       "3     01/16/2024 07:28:30         NaN            NaN       NaN            NaN   \n",
       "4     01/16/2024 07:29:30         NaN            NaN       NaN            NaN   \n",
       "...                   ...         ...            ...       ...            ...   \n",
       "6244     31/01/2024 16:01         NaN            NaN       NaN            NaN   \n",
       "6245     31/01/2024 16:02         NaN            NaN       NaN            NaN   \n",
       "6246     31/01/2024 16:03         NaN            NaN       NaN            NaN   \n",
       "6247     31/01/2024 16:04         NaN            NaN       NaN            NaN   \n",
       "6248     31/01/2024 16:05         NaN            NaN       NaN            NaN   \n",
       "\n",
       "       Veloc_2 CSSR  T_Globo OUT  Direcao OUT  Veloc OUT   T_ar CSLAB  \\\n",
       "0               NaN          NaN          NaN        NaN          NaN   \n",
       "1               NaN          NaN          NaN        NaN          NaN   \n",
       "2               NaN          NaN          NaN        NaN          NaN   \n",
       "3               NaN          NaN          NaN        NaN          NaN   \n",
       "4               NaN          NaN          NaN        NaN          NaN   \n",
       "...             ...          ...          ...        ...          ...   \n",
       "6244            NaN          NaN          NaN        NaN        26.97   \n",
       "6245            NaN          NaN          NaN        NaN        27.01   \n",
       "6246            NaN          NaN          NaN        NaN        27.10   \n",
       "6247            NaN          NaN          NaN        NaN        27.16   \n",
       "6248            NaN          NaN          NaN        NaN        27.14   \n",
       "\n",
       "       T_Globo CSLAB   UR CSLAB   Veloc_1 CSLAB   Veloc_2 CSLAB  \\\n",
       "0                NaN        NaN             NaN             NaN   \n",
       "1                NaN        NaN             NaN             NaN   \n",
       "2                NaN        NaN             NaN             NaN   \n",
       "3                NaN        NaN             NaN             NaN   \n",
       "4                NaN        NaN             NaN             NaN   \n",
       "...              ...        ...             ...             ...   \n",
       "6244           27.53      68.63            0.17            0.07   \n",
       "6245           27.58      68.39            0.16            0.17   \n",
       "6246           27.60      68.15            0.22            0.15   \n",
       "6247           27.63      67.96            0.20            0.15   \n",
       "6248           27.65      68.04            0.22            0.17   \n",
       "\n",
       "       Veloc_3 CSLAB  V_ar [m/s] TtSR  T_ar [°C] TtSR  T_globo [°C] TtSR  \\\n",
       "0                NaN              NaN             NaN                NaN   \n",
       "1                NaN              NaN             NaN                NaN   \n",
       "2                NaN              NaN             NaN                NaN   \n",
       "3                NaN              NaN             NaN                NaN   \n",
       "4                NaN              NaN             NaN                NaN   \n",
       "...              ...              ...             ...                ...   \n",
       "6244            0.30              NaN             NaN                NaN   \n",
       "6245            0.51              NaN             NaN                NaN   \n",
       "6246            0.48              NaN             NaN                NaN   \n",
       "6247            0.50              NaN             NaN                NaN   \n",
       "6248            0.48              NaN             NaN                NaN   \n",
       "\n",
       "      Temp °C HALL  RH % HALL  \n",
       "0              NaN        NaN  \n",
       "1              NaN        NaN  \n",
       "2              NaN        NaN  \n",
       "3              NaN        NaN  \n",
       "4              NaN        NaN  \n",
       "...            ...        ...  \n",
       "6244           NaN        NaN  \n",
       "6245           NaN        NaN  \n",
       "6246           NaN        NaN  \n",
       "6247           NaN        NaN  \n",
       "6248           NaN        NaN  \n",
       "\n",
       "[6249 rows x 20 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BaseDeDados_ambientais = BaseDeDados_ambientais.groupby('Date').agg('mean').reset_index()\n",
    "BaseDeDados_ambientais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados_ambientais = BaseDeDados_ambientais.dropna(how='all', subset=BaseDeDados_ambientais.columns[1:])\n",
    "BaseDeDados_ambientais.to_csv('BaseDeDados ambientais.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas vazias encontradas: Index([' T_ar CSSR', ' T_Globo CSSR', ' UR CSSR', ' Veloc_1 CSSR',\n",
      "       ' Veloc_2 CSSR', 'T_Globo OUT', 'Direcao OUT', 'Veloc OUT',\n",
      "       ' T_ar CSLAB', ' T_Globo CSLAB', ' UR CSLAB', ' Veloc_1 CSLAB',\n",
      "       ' Veloc_2 CSLAB', ' Veloc_3 CSLAB', 'V_ar [m/s] TtSR', 'T_ar [°C] TtSR',\n",
      "       'T_globo [°C] TtSR', 'Temp °C HALL', 'RH % HALL'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "colunas_vazias = BaseDeDados_ambientais.columns[BaseDeDados_ambientais.isnull().any()]\n",
    "if colunas_vazias.empty:\n",
    "    print(\"Não há colunas vazias.\")\n",
    "else:\n",
    "    print(\"Colunas vazias encontradas:\", colunas_vazias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mashup forms + \"ambientais/fisiologicos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivos_forms = [arquivo for arquivo in todos_arquivos if('Probral-Survey' in arquivo)]\n",
    "len(arquivos_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "for arquivo in arquivos_forms:\n",
    "    try:\n",
    "        arquivo_importo = pd.read_csv(arquivo)\n",
    "    except:\n",
    "        n += 1\n",
    "print(n)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
