{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic instructions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the '01. Outdoor-Indoor' past and copy paste it localization on the variavel seach_pattern_for_CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "04PmjXwf-Rwq"
   },
   "source": [
    "# Bibliotecas usadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q2tcc8yH-FpN"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pauRK7Fl-Ybr"
   },
   "source": [
    "# Bases \"fisiologicas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gAAhzRi7QHyS",
    "outputId": "26a198cd-5c10-417e-aad7-7930d5c9427e"
   },
   "outputs": [],
   "source": [
    "padrao_busca_csv = \"/Users/michi/Desktop/01. Outdoor-Indoor/01. LabEEE Experiments/**/*.csv\"\n",
    "todos_arquivos = glob.glob(padrao_busca_csv, recursive=True)\n",
    "\n",
    "ids = [\"IS\", \"LG\", \"LM\", \"MF\", \"TM\", \"ZM\", \"AW\", \"JF\", \"JP\", \"MN\", \"NC\", \"RM\"] \n",
    "nao = [\"01. Pilot LabEEE 20231114\", \"02. Pilot LabEEE 20231122\"]\n",
    "\n",
    "arquivos_fisiologicos = [arquivo for arquivo in todos_arquivos if any(sigla in arquivo for sigla in ids) and not any(nome in arquivo for nome in nao)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "relacao_tabela_informacao = {\"A (°C)\" :\t[\"4B00000069A8E941\",\"FE00000069AF1041\",\"B600000069B23241\",\"7D00000069AB4641\",\"0F00000069AAAF41\",\"C400000069ADCC41\"],\n",
    "                            \"D (°C)\":\t[\"CB00000069AD3041\",\"9400000069AA4941\",\"2700000069AD8541\",\"C100000069B26141\",\"CA00000069B19041\",\"4A00000069AC0841\"],\n",
    "                            \"F (°C)\":\t[\"C400000069AA8341\",\"C400000069B3DB41\",\"8100000069AE1641\",\"2700000069AACA41\",\"6700000069AEFC41\",\"1C00000069B3F941\"], \n",
    "                            \"H (°C)\":\t[\"B200000069AE3141\",\"EC00000069A9CD41\",\"3300000069AC2241\",\"3600000069AAD741\",\"E800000069AAC041\",\"AD00000069AF4C41\"],\n",
    "                            \"J (°C)\":\t[\"FA00000069AD0441\",\"3400000069B1AE41\",\"C700000069B34D41\",\"4B00000069B0A841\",\"0600000069B22741\",\"9100000069AAEA41\",\"6700000069AB8141\"],\n",
    "                            \"K (°C)\":\t[\"FB00000069B28F41\",\"7B00000069AA6A41\",\"E500000069AA2F41\",\"1A00000069A9BF41\",\"FE00000069B10741\",\"E100000069AD4641\"],\n",
    "                            \"M (°C)\":\t[\"1B00000069B06241\",\"8C00000069ADD241\",\"F000000069AF6941\",\"AA00000069AA8141\",\"1600000069ABE741\",\"A000000069AEBA41\"],\n",
    "                            \"O (°C)\":\t[\"7600000069AA8541\",\"F200000069B16D41\",\"3000000069A9C941\",\"BF00000069AFC741\",\"A300000069B12241\",\"D900000069ACA241\"],\n",
    "                            \"Q (°C)\":\t[\"8600000069B0B141\",\"6000000069AB3141\",\"DB00000069A9CC41\",\"EF00000069B23141\",\"6900000069AE8541\",\"4300000069B3CF41\"],\n",
    "                            \"T (°C)\":\t[\"7600000069AB9C41\",\"4500000069B1C841\",\"6600000069B25C41\",\"A200000069B0BE41\",\"D700000069B3D541\",\"9800000069B26241\",\"9E00000069AE7241\"],\n",
    "                            \"T_RH\" : [\"6E0000006CB57E41\",\t\"590000006CB46641\",\t\"4B0000006CBA7341\",\t\"D30000006CBD4C41\",\t\"370000006341C241\",\t\"9C000000633F9F41\"]}\n",
    "\n",
    "nomes = [\"Zac\", \"Joao\", \"Igor\", \"Luis\", \"Milena\", \"Ana\", \"Marcela\", \"Nathalia\", \"Thalita\", \"Liege\", \"Rayner\", \"João\"]\n",
    "sports = [\"WALKING\",\"CYCLING\",\"CROSS-COUNTRY_SKIING\",\"SKATING\",\"RIDING\",\"ROWING\"]\n",
    "\n",
    "ids_com_codigo = {\"IS\":'IS26', \"LG\":'LG37', \"LM\":'LM27', \"MF\":'MF36', \"TM\":'TM35', \"ZM\":'ZM26', \"AW\":'AW35', \"JF\":'JF25', \"JP\":'JP27', \"MN\":\"MN37\", \"NC\":\"NC36\", \"RM\":\"RM26\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verifica_qual_tipo_de_csv(titulo):\n",
    "    for chave, valores in relacao_tabela_informacao.items():\n",
    "        if titulo in valores:\n",
    "            return chave\n",
    "\n",
    "def convertepfloat(row):\n",
    "    n1 = str(row.iloc[2]).replace('.', '')\n",
    "    n2 = str(row.iloc[3]).replace('.', '')\n",
    "    return float(n1 + '.' + n2)\n",
    "\n",
    "def datamento(base_de_dados_crua, base_de_dados_nova):\n",
    "    dia = base_de_dados_crua.iloc[0,2]\n",
    "    dia = dia.replace('-','/')\n",
    "    hora_inicio = base_de_dados_crua.iloc[0,3]\n",
    "    data_inicio = dia + \" \" + hora_inicio\n",
    "    data_inicio = datetime.strptime(data_inicio, '%d/%m/%Y %H:%M:%S')\n",
    "    data_fim = dia + ' ' + '20:00:00'\n",
    "    data_fim = datetime.strptime(data_fim, '%d/%m/%Y %H:%M:%S')\n",
    "    intervalos_tempo = pd.date_range(start=data_inicio, end=data_fim, freq='s')\n",
    "    base_de_dados_nova['Date'] = intervalos_tempo[:len(base_de_dados_nova)]\n",
    "\n",
    "def limpeza_simples(id, arquivo, coluna):\n",
    "    colunas = [\"Date\", \"uni\", \"u\", \"d\"]\n",
    "    dados = pd.read_csv(arquivo, skiprows=20,names=colunas).fillna('0')\n",
    "    dados[f'{coluna}'] = dados.apply(lambda row: convertepfloat(row), axis=1)\n",
    "    dados = dados.iloc[:, [0,-1]]\n",
    "    dados['Date'] = pd.to_datetime(dados['Date'], format='%d/%m/%y %H:%M:%S')\n",
    "    return dados\n",
    "\n",
    "def calcular_TPond(row):\n",
    "    if all(row[['A (°C)', 'D (°C)', 'F (°C)', 'H (°C)', 'J (°C)', 'K (°C)', 'M (°C)', 'O (°C)', 'Q (°C)', 'T (°C)']].notnull()):\n",
    "        return float(0.07 * row['T (°C)'] + 0.13 * row['Q (°C)'] + 0.19 * row['O (°C)'] + 0.12 * row['M (°C)'] + 0.12 * row['K (°C)'] + 0.12 * row['J (°C)'] + 0.05 * row['H (°C)'] + 0.06 * row['F (°C)'] + 0.08 * row['D (°C)'] + 0.06 * row['A (°C)'])\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def atribuir_id(id, df):\n",
    "    for chave, valores in ids_com_codigo.items():\n",
    "        if id in valores:\n",
    "            df['id'] = chave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FY756p1DAJs9",
    "outputId": "b8de568b-1fd3-47b4-b41c-122f53345981"
   },
   "outputs": [],
   "source": [
    "col_names = ['id', 'Date', 'TPond (°C)', 'A (°C)', 'D (°C)', 'F (°C)', 'H (°C)', 'J (°C)', 'K (°C)', 'M (°C)', 'O (°C)', 'Q (°C)',\t'T (°C)', 'wHR (bpm)', 'cHR (bpm)', 'wU (bpm)', 'wT (°C)']\n",
    "BaseDeDados = pd.DataFrame(columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo in arquivos_fisiologicos:\n",
    "    ultimo_backslash = arquivo.rfind('\\\\')\n",
    "    ultimounderscore = arquivo.rfind('_')\n",
    "    titulo = arquivo[ultimo_backslash+1:ultimounderscore]\n",
    "    penultimo_backslash = arquivo.rfind('\\\\', 0, ultimo_backslash)\n",
    "    id = arquivo[penultimo_backslash+1:penultimo_backslash+3]\n",
    "    if \"Test+Room\" in titulo or any(name in titulo for name in nomes):\n",
    "        heart = pd.read_csv(arquivo).fillna('0')\n",
    "        if(heart.iloc[0,1] == \"OTHER_OUTDOOR\"):\n",
    "            pulso = pd.read_csv(arquivo, usecols=[\"HR (bpm)\"], skiprows=2)\n",
    "            datamento(heart,pulso)\n",
    "            atribuir_id(id,pulso)\n",
    "            pulso = pulso.rename(columns={'HR (bpm)': 'wHR (bpm)'})\n",
    "            BaseDeDados = pd.concat([BaseDeDados, pulso], ignore_index=True)\n",
    "        elif(heart.iloc[0,1] in sports):\n",
    "            peito = pd.read_csv(arquivo, usecols=[\"HR (bpm)\"], skiprows=2)\n",
    "            datamento(heart,peito)\n",
    "            atribuir_id(id,peito)\n",
    "            peito = peito.rename(columns={'HR (bpm)': 'cHR (bpm)'})\n",
    "            BaseDeDados = pd.concat([BaseDeDados, peito], ignore_index=True)\n",
    "        elif(heart.iloc[0,1] == \"False\" or \"True\"):\n",
    "            continue\n",
    "        else:\n",
    "            print(heart.iloc[0,1])    \n",
    "    elif(\"_U\" in arquivo) or (\"_T\" in arquivo) or (any(titulo in valores for valores in relacao_tabela_informacao.values())):\n",
    "        if(\"_T\" in arquivo):\n",
    "            coluna = 'wT (°C)'\n",
    "            temp = limpeza_simples(id, arquivo, coluna)\n",
    "            atribuir_id(id,temp)\n",
    "            BaseDeDados = pd.concat([BaseDeDados, temp],ignore_index=True)\n",
    "        elif(\"_U\" in arquivo):\n",
    "            coluna = 'wU (bpm)'\n",
    "            umid = limpeza_simples(id, arquivo, coluna)\n",
    "            atribuir_id(id,umid)\n",
    "            BaseDeDados = pd.concat([BaseDeDados, umid],ignore_index=True)\n",
    "        else:\n",
    "            coluna = verifica_qual_tipo_de_csv(titulo)\n",
    "            temp = limpeza_simples(id, arquivo, coluna)\n",
    "            atribuir_id(id,temp)\n",
    "            BaseDeDados = pd.concat([BaseDeDados, temp],ignore_index=True)\n",
    "    else:\n",
    "        print(titulo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados = BaseDeDados.groupby(['id', 'Date']).agg('mean').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados['TPond (°C)'] = BaseDeDados.apply(calcular_TPond, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados.to_csv('BaseDeDados.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ambientais + \"fisiologicas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "siglas_ambientais = ['CSLAB','CSSR','HALL','OUT','TtSR']\n",
    "arquivos_CSLAB = [arquivo for arquivo in todos_arquivos if 'CSLAB' in arquivo] \n",
    "arquivos_OUT = [arquivo for arquivo in todos_arquivos if 'OUT' in arquivo]\n",
    "arquivos_CSSR = [arquivo for arquivo in todos_arquivos if 'CSSR' in arquivo]\n",
    "arquivos_HALL = [arquivo for arquivo in todos_arquivos if 'HALL' in arquivo and 'excel' not in arquivo]\n",
    "arquivos_TtSR = [arquivo for arquivo in todos_arquivos if 'TtSR' in arquivo] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados_ambientais = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_cols(df, tipo):\n",
    "    df = df.rename(columns={'Data': 'Date'})\n",
    "    for coluna in df.columns[1:]:\n",
    "        if('Unnamed' in coluna):\n",
    "            df = df.drop(columns=[coluna])\n",
    "            continue\n",
    "        df = df.rename(columns={coluna: f\"{coluna} {tipo}\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo in arquivos_CSSR:\n",
    "    try:\n",
    "        importado = pd.read_csv(arquivo, sep=';')\n",
    "        importado = rename_cols(importado, 'CSSR')\n",
    "        importado = importado.iloc[:, [0,1,2,3,4,5]]\n",
    "        importado['Date'] = pd.to_datetime(importado['Date'], format='%d/%m/%Y %H:%M:%S')\n",
    "        BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, importado], ignore_index=True)\n",
    "    except:\n",
    "        print(arquivo)\n",
    "\n",
    "for i,arquivo in enumerate(arquivos_OUT):\n",
    "    try:\n",
    "        importado = pd.read_csv(arquivo, sep=';', usecols=['Data','T_Globo','Direcao','Veloc'])\n",
    "        importado = rename_cols(importado, 'OUT')\n",
    "        importado = importado.iloc[10:]\n",
    "        if(i==4) or (i == 5):\n",
    "            importado['Date'] = importado['Date'].apply(lambda x: x + ':00')\n",
    "        importado['Date'] = pd.to_datetime(importado['Date'], format='%d/%m/%Y %H:%M:%S')\n",
    "        BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, importado], ignore_index=True)\n",
    "    except:\n",
    "        print(arquivo)\n",
    "\n",
    "for i, arquivo in enumerate(arquivos_CSLAB):\n",
    "    try:\n",
    "        importado = pd.read_csv(arquivo, sep=';')\n",
    "        if(i==5):\n",
    "            importado = pd.read_csv(arquivo, sep=',')\n",
    "        importado = rename_cols(importado, 'CSLAB')\n",
    "        importado['Date'] = importado['Date'].apply(lambda x: x + ':00')\n",
    "        importado['Date'] = pd.to_datetime(importado['Date'], format='%d/%m/%Y %H:%M:%S')\n",
    "        BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, importado], ignore_index=True)  \n",
    "    except:\n",
    "        print(arquivo)\n",
    "\n",
    "arquivos_TtSR.pop(0)\n",
    "for arquivo in arquivos_TtSR:\n",
    "    TtSR = pd.read_csv(arquivo,encoding='latin1',delimiter=';',skiprows=1,skipfooter=40,engine='python') \n",
    "    TtSR = TtSR.iloc[:, [0,2,4,5]]\n",
    "    TtSR = TtSR.rename(columns={'Data/Hora':'Date','094 [m/s]':'V_ar [m/s] TtSR','491 [Â°C]':'T_ar [°C] TtSR','517 TC1 [Â°C]':'T_globo [°C] TtSR'})\n",
    "    TtSR['Date'] = pd.to_datetime(TtSR['Date'], format='%d/%m/%Y %H:%M:%S')\n",
    "    BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, TtSR], ignore_index=True)\n",
    "\n",
    "colunas_usadas = ['Date-Time (Brazil Standard Time)','Ch:1 - Temperature   (°C)','Ch:2 - RH   (%)']\n",
    "for arquivo in arquivos_HALL:\n",
    "    HALL = pd.read_csv(arquivo,encoding='latin1',delimiter=';', usecols=colunas_usadas)\n",
    "    HALL = HALL.rename(columns={'Date-Time (Brazil Standard Time)':'Date','Ch:1 - Temperature   (°C)':'Temp °C HALL','Ch:2 - RH   (%)':'RH % HALL'})\n",
    "    HALL['Date'] = pd.to_datetime(HALL['Date'], format='%m/%d/%Y %H:%M:%S')\n",
    "    BaseDeDados_ambientais = pd.concat([BaseDeDados_ambientais, HALL], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados_ambientais.to_csv('BaseDeDados ambientais.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseDeDados_final = pd.merge(BaseDeDados, BaseDeDados_ambientais, how = 'outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forms + \"ambientais/fisiologicos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados_qualitativos = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "arquivos_qualitativos  = [arquivo for arquivo in todos_arquivos if 'Probral' in arquivo and not 'Pilot' in arquivo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for arquivo in arquivos_qualitativos:\n",
    "    A = pd.read_csv(arquivo, encoding='latin-1',sep=',')\n",
    "    A.rename(columns={'Carimbo de data/hora':'Date'}, inplace=True)\n",
    "    print(A.head())\n",
    "    A['Date'] = pd.to_datetime(A['Date'], format='%d/%m/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dados_qualitativos.to_csv('Dados_qualitativos.csv', index=False, encoding='utf-8')\n",
    "BaseDeDados_final = pd.merge(BaseDeDados_final, Dados_qualitativos, how = 'outer')\n",
    "BaseDeDados_final.to_csv('BaseDeDados_final.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
